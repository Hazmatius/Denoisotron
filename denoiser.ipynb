{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ImportError",
     "evalue": "numpy.core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7c520084e802>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"<style>.container { width:100% !important; }</style>\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkornia\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m __all__ += [name for name in dir(_C)\n",
      "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import"
     ]
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import torch\n",
    "import kornia\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "import sys\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('.'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from helpers import Trainer\n",
    "from helpers import Logger\n",
    "from helpers import Trial\n",
    "from mibi_dataloader import MIBIData\n",
    "from modules import Denoiser\n",
    "from criteria import DenoiserLoss\n",
    "from modules import Estimator\n",
    "from criteria import EstimatorLoss\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "main_dir = '/home/hazmat/GitHub/Denoiser/'\n",
    "train_dir = main_dir + 'data/traindat/'\n",
    "test_dir = main_dir + 'data/testdat/'\n",
    "\n",
    "modl_dir = main_dir + 'models/'\n",
    "rslt_dir = main_dir + 'results/'\n",
    "\n",
    "train_ds = MIBIData(folder=train_dir, crop=255, scale=255, stride=8)\n",
    "test_ds = MIBIData(folder=test_dir, crop=255, scale=255, stride=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estimator_args = dict()\n",
    "estimator_args['dims'] =    [8, 8, 8, 8, 8, 8, 8, 1]\n",
    "estimator_args['kernels'] = [7, 7, 7, 7, 7, 7, 7, 7]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "estimator = Estimator(**estimator_args)\n",
    "estimator = Estimator.load_model(main_dir + 'estimator/models/estimator_saves/', 'model_10')\n",
    "\n",
    "estimator.cuda()\n",
    "estimator_logger = Logger(['loss'])\n",
    "estimator_trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # Estimator training parameters\n",
    "# estimator_train_args = dict()\n",
    "# estimator_train_args['lr'] = 0.00033\n",
    "# estimator_train_args['batch_size'] = 120\n",
    "# estimator_train_args['epochs'] = 5\n",
    "# estimator_train_args['report'] = 5\n",
    "# estimator_train_args['crop'] = 255\n",
    "# estimator_train_args['clip'] = 1\n",
    "# estimator_train_args['decay'] = 0\n",
    "# estimator_train_args['restart'] = False\n",
    "# estimator_train_args['epoch_frac'] = 0.001\n",
    "# # estimator_train_args['decay'] = 1e-5\n",
    "\n",
    "# # Estimator loss parameters\n",
    "# estimator_criterion = EstimatorLoss()\n",
    "\n",
    "# train_ds.set_crop(estimator_train_args['crop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# estimator.cuda()\n",
    "# estimator_train_args['continue'] = True\n",
    "# estimator_trainer.train(estimator, train_ds, estimator_criterion, estimator_logger, main_dir + 'estimator/models/', **estimator_train_args)\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lam = np.zeros((512,512))\n",
    "for i in range(512):\n",
    "    for j in range(512):\n",
    "        lam[i,j] = (512-i)+(j)\n",
    "lam = lam / 200\n",
    "lam = np.expand_dims(lam,0)\n",
    "lam = np.expand_dims(lam,0)\n",
    "# lam = np.tile(lam,[100,1,1,1])\n",
    "print(lam.shape)\n",
    "x = torch.tensor(np.random.poisson(lam,lam.shape)).float().cuda()\n",
    "lam = torch.tensor(lam).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = estimator.estimate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig0 = plt.figure(figsize=(9,3))\n",
    "_y = y*1.32\n",
    "plt.subplot(1,3,1)\n",
    "plt.imshow(lam[0,0,:,:].detach().cpu())\n",
    "plt.subplot(1,3,2)\n",
    "plt.imshow(_y[0,0,:,:].detach().cpu())\n",
    "plt.subplot(1,3,3)\n",
    "diff = torch.mean((lam-_y)**2)\n",
    "plt.imshow(lam[0,0,:,:].detach().cpu() - _y[0,0,:,:].detach().cpu())\n",
    "print(diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "# 12\n",
    "img = train_ds.images[0]\n",
    "img = img.unsqueeze(0).cuda()\n",
    "\n",
    "fig1 = plt.figure(figsize=(10,5))\n",
    "global img\n",
    "\n",
    "l_hat = estimator.estimate(img)\n",
    "l_hat = l_hat[0,0,:,:].detach().cpu()\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(img[0,0,:,:].detach().cpu())\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(l_hat)\n",
    "print(l_hat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "main_dir = '/home/hazmat/GitHub/Denoiser/'\n",
    "train_dir = main_dir + 'data/traindat/'\n",
    "test_dir = main_dir + 'data/testdat/'\n",
    "\n",
    "modl_dir = main_dir + 'models/'\n",
    "rslt_dir = main_dir + 'results/'\n",
    "\n",
    "# train_ds = MIBIData(folder=train_dir, crop=81, scale=255, stride=8)\n",
    "# test_ds = MIBIData(folder=test_dir, crop=81, scale=255, stride=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "denoiser_args = dict()\n",
    "denoiser_args['dims'] =    [8, 16, 32, 8, 1]\n",
    "denoiser_args['kernels'] = [3,  3,  3, 3, 3]\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "# denoiser = Denoiser(**denoiser_args)\n",
    "denoiser = Denoiser.load_model(main_dir + 'denoiser/models/2020Mar04_08-57-20/', 'model_9')\n",
    "\n",
    "denoiser.cuda()\n",
    "denoiser_logger = Logger(['loss'])\n",
    "denoiser_trainer = Trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Denoiser training parameters\n",
    "denoiser_train_args = dict()\n",
    "denoiser_train_args['lr'] = 0.0005\n",
    "denoiser_train_args['batch_size'] = 100\n",
    "denoiser_train_args['epochs'] = 100\n",
    "denoiser_train_args['report'] = 5\n",
    "denoiser_train_args['crop'] = 81\n",
    "denoiser_train_args['clip'] = 1\n",
    "denoiser_train_args['decay'] = 0\n",
    "denoiser_train_args['restart'] = False\n",
    "denoiser_train_args['epoch_frac'] = 0.01\n",
    "# denoiser_train_args['decay'] = 1e-5\n",
    "\n",
    "# Denoiser loss parameters\n",
    "denoiser_criterion = DenoiserLoss()\n",
    "\n",
    "train_ds.set_crop(denoiser_train_args['crop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "denoiser.cuda()\n",
    "denoiser_train_args['continue'] = False\n",
    "denoiser_trainer.train(denoiser, train_ds, denoiser_criterion, denoiser_logger, main_dir + 'denoiser/models/', **denoiser_train_args)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Denoiser training parameters\n",
    "denoiser_train_args = dict()\n",
    "denoiser_train_args['lr'] = 0.0005\n",
    "denoiser_train_args['batch_size'] = 100\n",
    "denoiser_train_args['epochs'] = 100\n",
    "denoiser_train_args['report'] = 5\n",
    "denoiser_train_args['crop'] = 81\n",
    "denoiser_train_args['clip'] = 1\n",
    "denoiser_train_args['decay'] = 0\n",
    "denoiser_train_args['restart'] = False\n",
    "denoiser_train_args['epoch_frac'] = 1\n",
    "# denoiser_train_args['decay'] = 1e-5\n",
    "\n",
    "# Denoiser loss parameters\n",
    "denoiser_criterion = DenoiserLoss()\n",
    "\n",
    "train_ds.set_crop(denoiser_train_args['crop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "denoiser.cuda()\n",
    "denoiser_train_args['continue'] = False\n",
    "denoiser_trainer.train(denoiser, train_ds, denoiser_criterion, denoiser_logger, main_dir + 'denoiser/models/', **denoiser_train_args)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lam = np.zeros((512,512))\n",
    "for i in range(512):\n",
    "    for j in range(512):\n",
    "        lam[i,j] = (512-i)+(j)\n",
    "lam = lam / 1000\n",
    "lam = np.expand_dims(lam,0)\n",
    "lam = np.expand_dims(lam,0)\n",
    "# lam = np.tile(lam,[100,1,1,1])\n",
    "print(lam.shape)\n",
    "x = torch.tensor(np.random.poisson(lam,lam.shape)).float().cuda()\n",
    "lam = torch.tensor(lam).float().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = estimator.estimate(x)\n",
    "z = denoiser.denoise(x, y*1.45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_scales = np.linspace(1.45,1.6,20)\n",
    "diffs = list()\n",
    "\n",
    "for y_scale in y_scales:\n",
    "    y = estimator.estimate(x)\n",
    "    z = denoiser.denoise(x, y*y_scale)\n",
    "    # tuning_fig = plt.figure(figsize=(8,4))\n",
    "    # plt.subplot(1,2,1)\n",
    "    # plt.imshow(x[0,0,:,:].detach().cpu())\n",
    "    # plt.subplot(1,2,2)\n",
    "    # plt.imshow(z[0,0,:,:].detach().cpu())\n",
    "    diff = torch.mean(z**2)\n",
    "    print(diff)\n",
    "    diffs.append(diff.detach().cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tuning_fig = plt.figure()\n",
    "plt.plot(y_scales, diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "leeat_ds = MIBIData(folder='/home/hazmat/GitHub/Denoiser/data/Point15/TIFs/', crop=81, scale=255, stride=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "img = leeat_ds.images[0]\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "fig1 = plt.figure(figsize=(14,7))\n",
    "global img\n",
    "\n",
    "def update(lam=0, cmax=1):\n",
    "    global img\n",
    "    x_lam = torch.zeros(img.shape)+lam\n",
    "    print(x_lam.shape)\n",
    "    dimg = denoiser.denoise(img.cuda(), x_lam)\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    kimg = img[0,0,:,:].cpu().detach()\n",
    "    kimg = kimg[10:-10:1, 10:-10:1]\n",
    "    plt.imshow(kimg, vmax=cmax)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original Image (CD14)')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    dimg = dimg[0,0,:,:].cpu().detach()\n",
    "    dimg = dimg[10:-10:1, 10:-10:1]\n",
    "    plt.imshow(dimg, vmax=cmax)\n",
    "    plt.axis('off')\n",
    "    plt.title('Denoised Image (CD14)')\n",
    "    \n",
    "#     plt.subplot(1,3,3)\n",
    "#     plt.imshow(kimg-dimg)\n",
    "#     plt.axis('off')\n",
    "#     plt.title('Difference')\n",
    "    \n",
    "    print(strftime('%H:%M:%S', gmtime()))\n",
    "    print(torch.mean(kimg-dimg))\n",
    "    \n",
    "interact(update, lam=widgets.FloatSlider(value=0.14, min=-0.1, max=100, step=0.01), cmax=widgets.IntSlider(value=3, min=0, max=20, step=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "img = test_ds.images[218]\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "fig1 = plt.figure(figsize=(14,7))\n",
    "global img\n",
    "\n",
    "def update(lam=0, cmax=1):\n",
    "    global img\n",
    "    x_lam = torch.zeros(img.shape)+lam\n",
    "    print(x_lam.shape)\n",
    "    dimg = denoiser.denoise(img.cuda(), x_lam)\n",
    "    \n",
    "    plt.subplot(1,2,1)\n",
    "    kimg = img[0,0,:,:].cpu().detach()\n",
    "    kimg = kimg[10:-10:1, 10:-10:1]\n",
    "    plt.imshow(kimg, vmax=cmax)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original Image (CD14)')\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    dimg = dimg[0,0,:,:].cpu().detach()\n",
    "    dimg = dimg[10:-10:1, 10:-10:1]\n",
    "    plt.imshow(dimg, vmax=cmax)\n",
    "    plt.axis('off')\n",
    "    plt.title('Denoised Image (CD14)')\n",
    "    \n",
    "#     plt.subplot(1,3,3)\n",
    "#     plt.imshow(kimg-dimg)\n",
    "#     plt.axis('off')\n",
    "#     plt.title('Difference')\n",
    "    \n",
    "    print(strftime('%H:%M:%S', gmtime()))\n",
    "    print(torch.mean(kimg-dimg))\n",
    "    \n",
    "interact(update, lam=widgets.FloatSlider(value=0.14, min=-0.1, max=1, step=0.01), cmax=widgets.IntSlider(value=3, min=0, max=20, step=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ipywidgets import *\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from time import gmtime, strftime\n",
    "\n",
    "\n",
    "\n",
    "# 12\n",
    "img = train_ds.images[0]\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "fig1 = plt.figure(figsize=(18,6))\n",
    "global img\n",
    "\n",
    "def update(kind=False, lam=0, cmax=1):\n",
    "    global img\n",
    "    \n",
    "    if not kind:\n",
    "        x_lam = torch.zeros(img.shape)+lam\n",
    "    else:\n",
    "        x_lam = gaussian_filter(img[0,0,:,:], sigma=200)\n",
    "        x_lam = torch.tensor(x_lam).unsqueeze(0).unsqueeze(0)*lam\n",
    "    \n",
    "    dimg = denoiser.denoise(img.cuda(), x_lam)\n",
    "    \n",
    "    plt.subplot(1,3,1)\n",
    "    plt.imshow(x_lam[0,0,:,:], vmin=0)\n",
    "    plt.axis('off')\n",
    "    plt.title('Lambda')\n",
    "    \n",
    "    plt.subplot(1,3,2)\n",
    "    kimg = img[0,0,:,:].cpu().detach()\n",
    "    kimg = kimg[10:-10:1, 10:-10:1]\n",
    "    plt.imshow(kimg, vmax=cmax)\n",
    "    plt.axis('off')\n",
    "    plt.title('Original Image (MAP2)')\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    dimg = dimg[0,0,:,:].cpu().detach()\n",
    "    dimg = dimg[10:-10:1, 10:-10:1]\n",
    "    plt.imshow(dimg, vmax=cmax)\n",
    "    plt.axis('off')\n",
    "    plt.title('Denoised Image (MAP2)')\n",
    "    \n",
    "    \n",
    "    print(strftime('%H:%M:%S', gmtime()))\n",
    "    print(torch.mean(kimg-dimg))\n",
    "    \n",
    "interact(update, kind=widgets.ToggleButton(value=True), lam=widgets.FloatSlider(value=1, min=0, max=1, step=0.01), cmax=widgets.IntSlider(value=3, min=0, max=20, step=1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
